import os
import pandas as pd
from typing import List, Dict, Any
import asyncio

import chromadb
import google.generativeai as genai

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=GOOGLE_API_KEY)


chroma_client = chromadb.PersistentClient(path="./chroma_db")
collection = chroma_client.get_or_create_collection(name="data_collection")


def get_gemini_embedding(text: str) -> List[float]:
    """[ë™ê¸°] Gemini APIë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (query_dbìš©)"""
    response = genai.embed_content(
        model="models/embedding-001",
        content=text
    )
    return response["embedding"]


async def get_gemini_embeddings_batch_async(texts: List[str]) -> List[List[float]]:
    """[ë¹„ë™ê¸°] Gemini APIë¡œ í…ìŠ¤íŠ¸ ë°°ì¹˜ì˜ ì„ë² ë”©ì„ ìƒì„±"""
    response = await genai.embed_content_async(
        model="models/embedding-001",
        content=texts,
        task_type="RETRIEVAL_DOCUMENT"
    )
    return response["embedding"]


async def add_df_to_db_async(df: pd.DataFrame, source_name: str = "uploaded_df", batch_size: int = 100):
    """
    [ë¹„ë™ê¸°] DataFrameì„ ë²¡í„° DBì— ì €ì¥ (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ ì ìš©)
    """
    docs, ids, metas = [], [], []
    for i, row in df.iterrows():
        row_values = [str(val) if pd.notna(val) else "" for val in row]
        row_text = ", ".join([f"{col}: {val}" for col, val in zip(df.columns, row_values)])
        doc_id = f"{source_name}_row{i}"
        docs.append(row_text)
        ids.append(doc_id)
        metas.append({"source": source_name, "row": int(i)})

    embedding_tasks = []
    for i in range(0, len(docs), batch_size):
        batch_docs_content = docs[i:i + batch_size]
        task = get_gemini_embeddings_batch_async(batch_docs_content)
        embedding_tasks.append(task)
    
    print(f"ğŸš€ Starting concurrent embedding for {len(embedding_tasks)} batches...")
    all_embeddings_results = await asyncio.gather(*embedding_tasks)
    print("âœ… All embeddings processed.")

    all_embeddings = [emb for batch_embs in all_embeddings_results for emb in batch_embs]
    
    for i in range(0, len(ids), batch_size):
        collection.add(
            ids=ids[i:i + batch_size],
            documents=docs[i:i + batch_size],
            embeddings=all_embeddings[i:i + batch_size],
            metadatas=metas[i:i + batch_size]
        )
        print(f"ğŸ“¦ Added batch {i // batch_size + 1} to ChromaDB.")

    print(f"âœ… Total {len(docs)} rows have been added to the Vector DB. (DataFrame: {source_name})")


def add_df_to_db(df: pd.DataFrame, source_name: str = "uploaded_df"):
    """DataFrameì„ ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    asyncio.run(add_df_to_db_async(df, source_name))


def add_csv_to_db(file_path: str):
    """CSV íŒŒì¼ì„ ì½ì–´ ë²¡í„° DBì— ì €ì¥"""
    df = pd.read_csv(file_path)
    source_name = os.path.basename(file_path)
    add_df_to_db(df, source_name=source_name)


def query_db(question: str, top_k: int = 3) -> List[dict]:
    """ì§ˆë¬¸ì„ ë°›ì•„ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ DBì—ì„œ ê²€ìƒ‰ (ë™ê¸° ë°©ì‹)"""
    q_emb = get_gemini_embedding(question)
    results = collection.query(
        query_embeddings=[q_emb],
        n_results=top_k
    )
    docs = results.get("documents", [[]])[0]
    metadatas = results.get("metadatas", [[]])[0]

    hits = []
    for i, doc in enumerate(docs):
        meta = metadatas[i] or {}
        hits.append({
            "text": doc,
            "source": meta.get("source"),
            "row": meta.get("row")
        })
    return hits


def clear_db():
    """ì»¬ë ‰ì…˜ ì „ì²´ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±"""
    try:
        chroma_client.delete_collection(name="data_collection")
        global collection
        collection = chroma_client.get_or_create_collection(name="data_collection")
        print("ğŸ§¹ ë²¡í„° DB ì™„ì „íˆ ì´ˆê¸°í™” ì™„ë£Œ (ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±).")
    except Exception as e:
        print("âš ï¸ ë²¡í„° DB ì´ˆê¸°í™” ì‹¤íŒ¨:", e)


if __name__ == "__main__":
    sample_data = {'col1': range(250), 'col2': [f'text_{i}' for i in range(250)]}
    sample_df = pd.DataFrame(sample_data)
    sample_df.to_csv("ìƒ˜í”Œë°ì´í„°.csv", index=False)
    
    add_csv_to_db("ìƒ˜í”Œë°ì´í„°.csv")
    q = "text_50ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì€?"
    answers = query_db(q)
    print("ê²€ìƒ‰ëœ ìœ ì‚¬ í…ìŠ¤íŠ¸:", answers)